{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"center\">\n",
    "    <h3>\n",
    "        بسم الله الرحمن الرحیم\n",
    "    </h3>\n",
    "    <br>\n",
    "    <h1>\n",
    "        <strong>\n",
    "            بازیابی پیشرفته اطلاعات\n",
    "        </strong>\n",
    "    </h1>\n",
    "    <h2>\n",
    "        <strong>\n",
    "            تمرین سوم (موتور جستجوی اخبار)\n",
    "        </strong>\n",
    "    </h2>\n",
    "    <br>\n",
    "    <h3>\n",
    "        محمد هجری - ٩٨١٠٦١٥٦\n",
    "        <br><br>\n",
    "        ارشان دلیلی - ٩٨١٠٥٧٥١\n",
    "        <br><br>\n",
    "        سروش جهان‌زاد - ٩٨١٠٠٣٨٩\n",
    "    </h3>\n",
    "    <br>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <h3 style='direction:rtl;text-align:justify;'>\n",
    "        نصب و دسترسی به کتابخانه‌های مورد نیاز\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        با اجرای دو قطعه کد زیر، کتابخانه‌هایی که از آن‌ها در این تمرین استفاده شده است، نصب و قابل استفاده می‌شوند.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install bs4\n",
    "# !pip install tqdm\n",
    "# !pip install pandas\n",
    "# !pip install requests\n",
    "# !pip install hazm\n",
    "# !pip install unidecode\n",
    "# !pip install pandas\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import hazm\n",
    "import nltk\n",
    "import pickle\n",
    "import zipfile\n",
    "import requests\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <h3 style='direction:rtl;text-align:justify;'>\n",
    "        ١. دریافت داده‌ها\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        در این تمرین، بیش از ٨٠ هزار خبر از\n",
    "        <a href=\"https://www.hamshahrionline.ir/\"> وب‌سایت همشهری‌آنلاین </a>\n",
    "        گردآوری شده که در ١٠ دسته‌ی سیاسی، جهانی، اقتصادی، اجتماعی، شهری، ورزشی، علمی، فرهنگی، فناوری اطلاعات و مهارت‌های زندگی طبقه‌بندی شده‌اند.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'Politics': 'سیاسی',\n",
    "    'World': 'جهانی',\n",
    "    'Economy': 'اقتصادی',\n",
    "    'Society': 'اجتماعی',\n",
    "    'City': 'شهری',\n",
    "    'Sport': 'ورزشی',\n",
    "    'Science': 'علمی',\n",
    "    'Culture': 'فرهنگی',\n",
    "    'IT': 'فناوری اطلاعات',\n",
    "    'LifeSkills': 'مهارت‌های زندگی',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        برای دریافت داده‌ها یک ماژول Scraper ساخته‌ایم که اخبار مربوط به ١٠ دسته‌ی مذکور را در بازه‌ی زمانی تعیین شده، کراول کرده و در فایل dataset.zip ذخیره و فشرده سازی می‌کند. کد مربوط به این ماژول را در زیر مشاهده می‌کنید.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "\n",
    "    def __init__(self, current_year, current_month):\n",
    "        self.current_year = current_year\n",
    "        self.current_month = current_month\n",
    "\n",
    "    def get_URL_content(self, URL):\n",
    "        while True:\n",
    "            try:\n",
    "                return requests.get(URL, timeout=5).content\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def generate_page_URL(self, page_index, category, year, month):\n",
    "        tp = {'Politics': 6, 'World': 11, 'Economy': 10, 'Society': 5, 'City': 7,\n",
    "              'Sport': 9, 'Science': 20, 'Culture': 26, 'IT': 718, 'LifeSkills': 21}[category]\n",
    "        return f'https://www.hamshahrionline.ir/archive?pi={page_index}&tp={tp}&ty=1&ms=0&mn={month}&yr={year}'\n",
    "\n",
    "    def get_page_URLs_by_time(self, category, year, month):\n",
    "        URLs = []\n",
    "        page_index = 1\n",
    "        while True:\n",
    "            URL = self.generate_page_URL(page_index, category, year, month)\n",
    "            content = self.get_URL_content(URL)\n",
    "            if re.findall('pagination', str(content)):\n",
    "                URLs.append(URL)\n",
    "                page_index += 1\n",
    "            else:\n",
    "                break\n",
    "        return URLs\n",
    "\n",
    "    def get_page_URLs_since(self, category, year, month):\n",
    "        URLs = []\n",
    "        with tqdm() as pbar:\n",
    "            while True:\n",
    "                if month > 12:\n",
    "                    month = 1\n",
    "                    year += 1\n",
    "                pbar.set_description(f'[{category}] [Extracting page URLs] [Date: {year}/{month}]')\n",
    "                URLs_by_time = self.get_page_URLs_by_time(category, year, month)\n",
    "                if URLs_by_time:\n",
    "                    for URL in URLs_by_time:\n",
    "                        URLs.append(URL)\n",
    "                    month += 1\n",
    "                elif self.current_year > year or (self.current_year == year and self.current_month > month):\n",
    "                    month += 1\n",
    "                else:\n",
    "                    break\n",
    "        return URLs\n",
    "\n",
    "    def get_news_URLs_since(self, category, year, month):\n",
    "        news_URLs = []\n",
    "        page_URLs = self.get_page_URLs_since(category, year, month)\n",
    "        with tqdm(page_URLs) as pbar:\n",
    "            for page_URL in pbar:\n",
    "                content = self.get_URL_content(page_URL)\n",
    "                soup = BeautifulSoup(content, 'html5lib')\n",
    "                for item in soup.findAll('li', attrs={'class': 'news'}):\n",
    "                    URL = item.find('div', attrs={'class': 'desc'}).find('h3').find('a')['href']\n",
    "                    URL = 'https://www.hamshahrionline.ir' + URL\n",
    "                    news_URLs.append(URL)\n",
    "                pbar.set_description(f'[{category}] [Extracting news URLs] [{len(news_URLs)} news until now]')\n",
    "        return news_URLs\n",
    "\n",
    "    def parse_news(self, URL, category):\n",
    "        try:\n",
    "            content = self.get_URL_content(URL)\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            date = soup.find('div', {'class': 'col-6 col-sm-4 col-xl-4 item-date'}).span.text.strip()\n",
    "            title = soup.find('div', {'class': 'item-title'}).h1.text.strip()\n",
    "            intro = soup.find('p', {'class': 'introtext', 'itemprop': 'description'}).text.strip()\n",
    "            body = soup.find('div', {'class': 'item-text', 'itemprop': 'articleBody'}).text.strip()\n",
    "            return {\n",
    "                'date': date,\n",
    "                'title': title,\n",
    "                'intro': intro,\n",
    "                'body': body,\n",
    "                'category': category,\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def scrape(self, from_year, from_month):\n",
    "        categories = ['Politics', 'World', 'Economy', 'Society', 'City',\n",
    "                      'Sport', 'Science', 'Culture', 'IT', 'LifeSkills']\n",
    "        news = []\n",
    "        for category in categories:\n",
    "            URLs = self.get_news_URLs_since(category, from_year, from_month)\n",
    "            with tqdm(URLs) as pbar:\n",
    "                pbar.set_description(f'[{category}] [Scraping news]')\n",
    "                for URL in pbar:\n",
    "                    news.append(self.parse_news(URL, category))\n",
    "        news = list(filter(None, news))\n",
    "        pd.DataFrame(news).to_csv(f'dataset.csv', encoding='utf-8')\n",
    "        with zipfile.ZipFile('dataset.zip', 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            zip_file.write('dataset.csv')\n",
    "        os.remove('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        با اجرای قطعه کد زیر، یک instance از ماژول Scraper ایجاد شده و شروع به دریافت و ذخیره‌سازی داده‌ها می‌کند. خبرهای دریافت شده همگی مربوط به قرن جدید، از سال ١٤٠٠ به بعد هستند.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scraper = Scraper(current_year=1401, current_month=3)\n",
    "# scraper.scrape(from_year=1400, from_month=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        بعد از ذخیره شدن داده‌ها در فایل فشرده dataset.zip، آن‌ها را از این فایل استخراج کرده و وارد برنامه می‌کنیم. با اجرای قطعه کد زیر، تعداد خبرهای هر دسته و تعداد کل خبرها را می‌توان مشاهده کرد.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_dataset_from_file():\n",
    "    dataset = []\n",
    "    with zipfile.ZipFile('dataset.zip', 'r') as zip_file:\n",
    "        zip_file.extractall()\n",
    "    with open('dataset.csv', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            data = dict(zip(header[1:], row[1:]))\n",
    "            dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame(read_dataset_from_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "    با اجرای قطعه کد زیر، تعداد خبرهای هر دسته و تعداد کل خبرها را می‌توان مشاهده کرد.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               دسته  تعداد\n0          کل خبرها  68362\n1             سیاسی  15798\n2             جهانی   2895\n3           اقتصادی   8900\n4           اجتماعی  13585\n5              شهری   3853\n6             ورزشی   8348\n7              علمی   3190\n8            فرهنگی   6512\n9    فناوری اطلاعات    437\n10  مهارت‌های زندگی   4844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>دسته</th>\n      <th>تعداد</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>کل خبرها</td>\n      <td>68362</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سیاسی</td>\n      <td>15798</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>جهانی</td>\n      <td>2895</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>اقتصادی</td>\n      <td>8900</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اجتماعی</td>\n      <td>13585</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>شهری</td>\n      <td>3853</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ورزشی</td>\n      <td>8348</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>علمی</td>\n      <td>3190</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>فرهنگی</td>\n      <td>6512</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>فناوری اطلاعات</td>\n      <td>437</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>مهارت‌های زندگی</td>\n      <td>4844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_dataset_info():\n",
    "    global CATEGORIES, dataset\n",
    "\n",
    "    length_dict = {key: 0 for key in CATEGORIES.keys()}\n",
    "    for _, data in dataset.iterrows():\n",
    "        length_dict[data['category']] += 1\n",
    "\n",
    "    df_dict = {\n",
    "        'دسته': CATEGORIES.values(),\n",
    "        'تعداد': length_dict.values(),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df.index += 1\n",
    "    df.loc[0] = ['کل خبرها', len(dataset)]\n",
    "    df = df.sort_index()\n",
    "    display(df)\n",
    "\n",
    "\n",
    "display_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <h3 style='direction:rtl;text-align:justify;'>\n",
    "        ٢. پیش پردازش اولیه‌ی متن\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        ابزار مورد استفاده برای پیش‌پردازش متن ورودی به صورت ماژولار طراحی شده است؛ به طوری که با صدا زدن تابع preprocess از آن، متن داده شده با عبور از یک خط لوله به صورت مرحله به مرحله تغییر می‌کند تا به یک ساختار استاندارد برسد. این مراحل عبارتند از:\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        نرمال سازی داده‌ها (normalize)\n",
    "    </li>\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        حذف لینک‌ها (remove_links)\n",
    "    </li>\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        حذف نشانه‌های نگارشی (remove_punctuations)\n",
    "    </li>\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        واحد سازی داده‌ها (word_tokenize)\n",
    "    </li>\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        حذف کلمات نامعتبر (remove_invalid_words)\n",
    "    </li>\n",
    "    <li style='direction:rtl;text-align:justify;'>\n",
    "        حذف ایست‌واژه‌ها (remove_stopwords)\n",
    "    </li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "\n",
    "    def __init__(self, stopwords_path):\n",
    "        self.stopwords = []\n",
    "        with open(stopwords_path, encoding='utf-8') as file:\n",
    "            self.stopwords = file.read().split()\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = self.normalize(text)\n",
    "        text = self.remove_links(text)\n",
    "        text = self.remove_punctuations(text)\n",
    "        words = self.word_tokenize(text)\n",
    "        words = self.remove_invalid_words(words)\n",
    "        words = self.remove_stopwords(words)\n",
    "        return words\n",
    "\n",
    "    def normalize(self, text):\n",
    "        return hazm.Normalizer().normalize(text)\n",
    "\n",
    "    def remove_links(self, text):\n",
    "        patterns = ['\\S*http\\S*', '\\S*www\\S*', '\\S+\\.ir\\S*', '\\S+\\.com\\S*', '\\S+\\.org\\S*', '\\S*@\\S*']\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, ' ', text)\n",
    "        return text\n",
    "\n",
    "    def remove_punctuations(self, text):\n",
    "        return re.sub(f'[{punctuation}؟،٪×÷»«]+', '', text)\n",
    "\n",
    "    def word_tokenize(self, text):\n",
    "        return hazm.word_tokenize(text)\n",
    "\n",
    "    def remove_invalid_words(self, words):\n",
    "        return [word for word in words if len(word) > 3 or re.match('^[\\u0600-\\u06FF]{2,3}$', word)]\n",
    "\n",
    "    def remove_stopwords(self, words):\n",
    "        return [word for word in words if word not in self.stopwords]\n",
    "\n",
    "\n",
    "def save_preprocessed_texts(texts, path=\"Preprocessed_texts.pickle\"):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(texts, file)\n",
    "\n",
    "\n",
    "def load_preprocessed_texts(path=\"Preprocessed_texts.pickle\"):\n",
    "    with open(path, \"rb\") as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        با اجرای قطعه کد زیر، یک instance از ماژول Preprocessor ایجاد کرده و شروع به پیش پردازش داده‌ها می‌کنیم.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_to_text(data):\n",
    "    return ' '.join([data['title'], data['intro'], data['body']]).lower()\n",
    "\n",
    "\n",
    "preprocessor = Preprocessor(stopwords_path='stopwords.txt')\n",
    "\n",
    "# texts = [data_to_text(data) for _, data in dataset.iterrows()]\n",
    "# preprocessed_texts = [preprocessor.preprocess(text) for text in tqdm(texts)]\n",
    "# save_preprocessed_texts(preprocessed_texts)\n",
    "\n",
    "preprocessed_texts = load_preprocessed_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "## Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def get_mini_dataset(len_each_category=400):\n",
    "    global CATEGORIES, dataset\n",
    "\n",
    "    mini_dataset = []\n",
    "    for category in CATEGORIES.keys():\n",
    "        dataset_by_category = dataset.loc[dataset['category'] == category]\n",
    "        length = min(len_each_category, dataset_by_category.shape[0])\n",
    "        mini_dataset.append(dataset_by_category.sample(length, random_state=1))\n",
    "\n",
    "    mini_dataset = pd.concat(mini_dataset).reset_index(drop=True)\n",
    "    texts = [data_to_text(data) for _, data in mini_dataset.iterrows()]\n",
    "    mini_preprocessed_texts = [preprocessor.preprocess(text) for text in tqdm(texts)]\n",
    "    return mini_dataset, mini_preprocessed_texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanIR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(binary=True)\n",
    "        self.vectors = None\n",
    "        self.words = None\n",
    "        self.dense_vectors_df = None\n",
    "\n",
    "    def fit_transform_vectorizer(self, dataset):\n",
    "        self.vectors = self.vectorizer.fit_transform(list(map(lambda doc: ' '.join(doc), dataset)))\n",
    "        self.words = self.vectorizer.get_feature_names_out()\n",
    "        dense_vectors = self.vectors.todense().tolist()\n",
    "        self.dense_vectors_df = pd.DataFrame(dense_vectors, columns=self.words)\n",
    "\n",
    "    def predict(self, query, dataset, k):\n",
    "        query_transform = self.vectorizer.transform([query]).todense().tolist()[0]\n",
    "        query_indices = np.nonzero(query_transform)[0]\n",
    "        query_result = []\n",
    "        for index, doc in self.dense_vectors_df.iterrows():\n",
    "            if all(np.take(doc, query_indices)):\n",
    "                query_result.append(index)\n",
    "            if len(query_result) == k:\n",
    "                break\n",
    "        return dataset.iloc[query_result]\n",
    "\n",
    "\n",
    "def save_boolean_model(model, path=\"BooleanIR_model.pickle\"):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "\n",
    "def load_boolean_model(path=\"BooleanIR_model.pickle\"):\n",
    "    with open(path, \"rb\") as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:22<00:00, 177.74it/s]\n"
     ]
    }
   ],
   "source": [
    "mini_dataset, mini_preprocessed_texts = get_mini_dataset()\n",
    "\n",
    "booleanIR_model = BooleanIR()\n",
    "booleanIR_model.fit_transform_vectorizer(mini_preprocessed_texts)\n",
    "save_boolean_model(booleanIR_model)\n",
    "\n",
    "# booleanIR_model = load_boolean_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                 date  \\\n155  چهارشنبه ۱۷ فروردین ۱۴۰۱ - ۰۸:۴۵   \n266         شنبه ۷ اسفند ۱۴۰۰ - ۰۷:۴۶   \n296      شنبه ۲۰ فروردین ۱۴۰۱ - ۰۸:۱۴   \n404  پنجشنبه ۱۵ اردیبهشت ۱۴۰۱ - ۰۳:۳۵   \n416    یکشنبه ۱۴ فروردین ۱۴۰۱ - ۰۲:۵۱   \n418   سه‌شنبه ۱۶ فروردین ۱۴۰۱ - ۱۸:۳۵   \n420     پنجشنبه ۱۹ اسفند ۱۴۰۰ - ۱۴:۵۱   \n421    دوشنبه ۵ اردیبهشت ۱۴۰۱ - ۰۱:۴۹   \n424      جمعه ۱۲ فروردین ۱۴۰۱ - ۱۲:۲۷   \n433  سه‌شنبه ۲۰ اردیبهشت ۱۴۰۱ - ۱۴:۳۵   \n\n                                                 title  \\\n155  فرید زکریا: اقدامات دولت بایدن دشمنان آمریکا ر...   \n266  با این روند پوتین مرد شماره یک جهان می‌شود | غ...   \n296  روایت نیویورک‌تایمز از دلیل حضور نداشتن آمریکا...   \n404  سوئد می‌گوید برای پیوستن به ناتو از آمریکا تضم...   \n416  پاپ فرانسیس ممکن است به کی‌یف سفر کند| انتقاد ...   \n418  اتحادیه اروپا دور پنجم تحریم‌ها بر ضد روسیه را...   \n420  الیگارش‌های روس در انگلیس تحریم می‌شوند| آبرام...   \n421  اوکراین می‌گوید نیروهای روسیه قصد تصرف کارخانه...   \n424  انفجار در انبار نفت بلگورود روسیه | فرماندار: ...   \n433  رئیس‌ جهموری جدید کره‌جنوبی را بهتر بشناسیم | ...   \n\n                                                 intro  \\\n155  فرید زکریا تحلیلگر ارشد آمریکایی در روزنامه وا...   \n266  یک کارشناس مسائل بین الملل و استاد دانشگاه گفت...   \n296  روزنامه نیویورک‌تایمز تأکید کرد: آمریکا در مذا...   \n404  وزیر خارجه سوئد گفت آمریکا به این کشور تضمین د...   \n416  پاپ فرانسیس گفته است در حال بررسی دیدار از شهر...   \n418  اوزولا فون در لاین، رئیس کمیسیون اروپا اعلام ک...   \n420  دولت انگلیس رومن آبراموویچ، صاحب باشگاه فوتبال...   \n421  مقامات اوکراینی روز یکشنبه گفتند نیروهای روسیه...   \n424  فرماندار منطقه بلگورود روسیه مدعی شد که بالگرد...   \n433  یون سوک یول، رئیس‌جمهوری کره‌جنوبی اگرچه در عر...   \n\n                                                  body  category  \n155  به گزارش همشهری آنلاین به نقل از کیهان، یکی از...  Politics  \n266  محمد بیاتی - همشهری آنلاین: علی بیگدلی معتقد ا...  Politics  \n296  به گزرش همشهری آنلاین به نقل از کیهان، این روز...  Politics  \n404  به گزارش همشهری آنلاین به نقل از رویترز آنا لی...     World  \n416  به گزارش همشهری آنلاین به نقل از گاردین رئیس ک...     World  \n418  به گزارش همشهری آنلاین به نقل از گاردین اوزولا...     World  \n420  به گزارش همشهری آنلاین به نقل از گاردین وزارت ...     World  \n421  به گزارش همشهری آنلاین به نقل از رویترز فرماند...     World  \n424  به گزارش همشهری آنلاین و به نقل از شبکه خبری ب...     World  \n433  به گزارش همشهری‌ آنلاین و به نقل از فرانس۲۴، ی...     World  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>title</th>\n      <th>intro</th>\n      <th>body</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>155</th>\n      <td>چهارشنبه ۱۷ فروردین ۱۴۰۱ - ۰۸:۴۵</td>\n      <td>فرید زکریا: اقدامات دولت بایدن دشمنان آمریکا ر...</td>\n      <td>فرید زکریا تحلیلگر ارشد آمریکایی در روزنامه وا...</td>\n      <td>به گزارش همشهری آنلاین به نقل از کیهان، یکی از...</td>\n      <td>Politics</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>شنبه ۷ اسفند ۱۴۰۰ - ۰۷:۴۶</td>\n      <td>با این روند پوتین مرد شماره یک جهان می‌شود | غ...</td>\n      <td>یک کارشناس مسائل بین الملل و استاد دانشگاه گفت...</td>\n      <td>محمد بیاتی - همشهری آنلاین: علی بیگدلی معتقد ا...</td>\n      <td>Politics</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>شنبه ۲۰ فروردین ۱۴۰۱ - ۰۸:۱۴</td>\n      <td>روایت نیویورک‌تایمز از دلیل حضور نداشتن آمریکا...</td>\n      <td>روزنامه نیویورک‌تایمز تأکید کرد: آمریکا در مذا...</td>\n      <td>به گزرش همشهری آنلاین به نقل از کیهان، این روز...</td>\n      <td>Politics</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>پنجشنبه ۱۵ اردیبهشت ۱۴۰۱ - ۰۳:۳۵</td>\n      <td>سوئد می‌گوید برای پیوستن به ناتو از آمریکا تضم...</td>\n      <td>وزیر خارجه سوئد گفت آمریکا به این کشور تضمین د...</td>\n      <td>به گزارش همشهری آنلاین به نقل از رویترز آنا لی...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>یکشنبه ۱۴ فروردین ۱۴۰۱ - ۰۲:۵۱</td>\n      <td>پاپ فرانسیس ممکن است به کی‌یف سفر کند| انتقاد ...</td>\n      <td>پاپ فرانسیس گفته است در حال بررسی دیدار از شهر...</td>\n      <td>به گزارش همشهری آنلاین به نقل از گاردین رئیس ک...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>سه‌شنبه ۱۶ فروردین ۱۴۰۱ - ۱۸:۳۵</td>\n      <td>اتحادیه اروپا دور پنجم تحریم‌ها بر ضد روسیه را...</td>\n      <td>اوزولا فون در لاین، رئیس کمیسیون اروپا اعلام ک...</td>\n      <td>به گزارش همشهری آنلاین به نقل از گاردین اوزولا...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>420</th>\n      <td>پنجشنبه ۱۹ اسفند ۱۴۰۰ - ۱۴:۵۱</td>\n      <td>الیگارش‌های روس در انگلیس تحریم می‌شوند| آبرام...</td>\n      <td>دولت انگلیس رومن آبراموویچ، صاحب باشگاه فوتبال...</td>\n      <td>به گزارش همشهری آنلاین به نقل از گاردین وزارت ...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>دوشنبه ۵ اردیبهشت ۱۴۰۱ - ۰۱:۴۹</td>\n      <td>اوکراین می‌گوید نیروهای روسیه قصد تصرف کارخانه...</td>\n      <td>مقامات اوکراینی روز یکشنبه گفتند نیروهای روسیه...</td>\n      <td>به گزارش همشهری آنلاین به نقل از رویترز فرماند...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>جمعه ۱۲ فروردین ۱۴۰۱ - ۱۲:۲۷</td>\n      <td>انفجار در انبار نفت بلگورود روسیه | فرماندار: ...</td>\n      <td>فرماندار منطقه بلگورود روسیه مدعی شد که بالگرد...</td>\n      <td>به گزارش همشهری آنلاین و به نقل از شبکه خبری ب...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>سه‌شنبه ۲۰ اردیبهشت ۱۴۰۱ - ۱۴:۳۵</td>\n      <td>رئیس‌ جهموری جدید کره‌جنوبی را بهتر بشناسیم | ...</td>\n      <td>یون سوک یول، رئیس‌جمهوری کره‌جنوبی اگرچه در عر...</td>\n      <td>به گزارش همشهری‌ آنلاین و به نقل از فرانس۲۴، ی...</td>\n      <td>World</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"روسیه به اوکراین حمله کرد\"\n",
    "preprocessed_query = ' '.join(preprocessor.preprocess(query))\n",
    "booleanIR_model.predict(preprocessed_query, mini_dataset, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.vectors = None\n",
    "        self.words = None\n",
    "        self.dense_vectors_df = None\n",
    "\n",
    "    def fit_transform_vectorizer(self, dataset):\n",
    "        self.vectors = self.vectorizer.fit_transform(list(map(lambda doc: ' '.join(doc), dataset)))\n",
    "        self.words = self.vectorizer.get_feature_names_out()\n",
    "        dense_vectors = self.vectors.todense().tolist()\n",
    "        self.dense_vectors_df = pd.DataFrame(dense_vectors, columns=self.words)\n",
    "\n",
    "    def predict(self, query, dataset, k):\n",
    "        query_transform = self.vectorizer.transform([query]).todense().tolist()[0]\n",
    "        dense_vectors = self.dense_vectors_df.values.tolist()\n",
    "        df_cosine_sim = list(map(lambda doc: self.cosine_sim(query_transform, doc), dense_vectors))\n",
    "        self.dense_vectors_df['query_sim'] = df_cosine_sim\n",
    "        indices = self.dense_vectors_df.nlargest(k, 'query_sim').index\n",
    "        self.dense_vectors_df = self.dense_vectors_df.drop(columns=['query_sim'])\n",
    "        return dataset.iloc[indices]\n",
    "\n",
    "    def cosine_sim(self, query, doc):\n",
    "        return np.dot(query, doc) / (np.linalg.norm(query) * np.linalg.norm(doc))\n",
    "\n",
    "\n",
    "def save_TF_IDF_model(model, path=\"TF_IDF_model.pickle\"):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "\n",
    "def load_TF_IDF_model(path=\"TF_IDF_model.pickle\"):\n",
    "    with open(path, \"rb\") as file:\n",
    "        return pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:21<00:00, 189.17it/s]\n"
     ]
    }
   ],
   "source": [
    "mini_dataset, mini_preprocessed_texts = get_mini_dataset()\n",
    "\n",
    "TF_IDF_model = TF_IDF()\n",
    "TF_IDF_model.fit_transform_vectorizer(mini_preprocessed_texts)\n",
    "save_TF_IDF_model(TF_IDF_model)\n",
    "\n",
    "# TF_IDF_model = load_TF_IDF_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                  date  \\\n733       پنجشنبه ۵ اسفند ۱۴۰۰ - ۱۰:۲۸   \n501        یکشنبه ۱ اسفند ۱۴۰۰ - ۰۸:۴۹   \n444        دوشنبه ۲۵ بهمن ۱۴۰۰ - ۰۸:۲۴   \n3271  سه‌شنبه ۲۰ اردیبهشت ۱۴۰۱ - ۱۷:۱۳   \n571        یکشنبه ۲۴ بهمن ۱۴۰۰ - ۱۱:۲۹   \n760      سه‌شنبه ۱۰ اسفند ۱۴۰۰ - ۱۳:۱۱   \n764          جمعه ۶ اسفند ۱۴۰۰ - ۱۲:۱۹   \n578          جمعه ۶ اسفند ۱۴۰۰ - ۱۶:۰۷   \n589      شنبه ۱۷ اردیبهشت ۱۴۰۱ - ۱۶:۲۷   \n460        یکشنبه ۸ اسفند ۱۴۰۰ - ۱۶:۱۰   \n\n                                                  title  \\\n733   ببینید | اوکراین؛ از آژیر حمله هوایی تا آتش سو...   \n501   هشدار درباره نزدیکی جنگ جهانی سوم | روسیه قصد ...   \n444   روسیه ژست حمله به اوکراین را گرفت | شاید چین ه...   \n3271  حمله سایبری به اینترنت ماهواه‌ای کار روسیه بود...   \n571                  حمله قریب‌الوقوع روسیه به اوکراین؟   \n760   تازه‌ترین درخواست وزیر امور خارجه اوکراین علیه...   \n764   ادعای وزیر دفاع انگلیس درباره نقشه روسیه برای ...   \n578   پوتین: آماده مذاکره با اوکراین هستیم | موضع ری...   \n589      جنگ اوکراین روزانه چقدر برای روسیه آب می‌خورد؟   \n460   منتظر جنگ جهانی سوم باشیم؟ | امکان چریکی شدن ج...   \n\n                                                  intro  \\\n733   رئیس جمهوری روسیه صبح امروز اعلام کرد که در پا...   \n501   بوریس جانسون، نخست وزیر انگلیس هشدار داد که وض...   \n444   یک استاد ژئوپلیتیک دانشگاه با اشاره به اینکه ر...   \n3271  اتحادیه اروپا مدعی شد که حمله سایبری بزرگ علیه...   \n571   یک مقام کاخ الیزه می‌گوید در تماس تلفنی رئیس ج...   \n760   دیمیترو کولبا، وزیر امور خارجه اوکراین، پس از ...   \n764   وزیر دفاع انگلیس در بیانیه‌ای مدعی شد، روسیه ق...   \n578   رئیس جمهور چین در یک تماس تلفنی با رئیس جمهور ...   \n589   یک نشریه آمریکایی در گزارشی با اشاره به سومین ...   \n460   جهانگیر کرمی، عضو هیات علمی دانشگاه تهران و کا...   \n\n                                                   body category  \n733   به گزارش همشهری آنلاین به نقل از تسنیم، شورای ...    World  \n501   به گزارش همشهری آنلاین به نقل از ایسنا، جانسون...    World  \n444   به گزلرش همشهری آنلاین، عبدالرضا فرجی راد دربا...    World  \n3271  به گزارش همشهری آنلاین و به نقل خبرگزاری رویتر...       IT  \n571   به گزارش همشهری آنلاین به نقل از فارس، یک مقام...    World  \n760   به گزارش همشهری آنلاین و به نقل از گاردین، او ...    World  \n764   به گزارش همشهری آنلاین و به نقل از گاردین، بن ...    World  \n578   به گزارش همشهری‌آنلاین به نقل از فارس، رسانه‌ه...    World  \n589   به گزارش همشهری‌آنلاین، ایرنا به نقل از نشریه ...    World  \n460   همشهری‌آنلاین - اصغر صوفی: درگیری میان اوکراین...    World  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>title</th>\n      <th>intro</th>\n      <th>body</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>733</th>\n      <td>پنجشنبه ۵ اسفند ۱۴۰۰ - ۱۰:۲۸</td>\n      <td>ببینید | اوکراین؛ از آژیر حمله هوایی تا آتش سو...</td>\n      <td>رئیس جمهوری روسیه صبح امروز اعلام کرد که در پا...</td>\n      <td>به گزارش همشهری آنلاین به نقل از تسنیم، شورای ...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>یکشنبه ۱ اسفند ۱۴۰۰ - ۰۸:۴۹</td>\n      <td>هشدار درباره نزدیکی جنگ جهانی سوم | روسیه قصد ...</td>\n      <td>بوریس جانسون، نخست وزیر انگلیس هشدار داد که وض...</td>\n      <td>به گزارش همشهری آنلاین به نقل از ایسنا، جانسون...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>444</th>\n      <td>دوشنبه ۲۵ بهمن ۱۴۰۰ - ۰۸:۲۴</td>\n      <td>روسیه ژست حمله به اوکراین را گرفت | شاید چین ه...</td>\n      <td>یک استاد ژئوپلیتیک دانشگاه با اشاره به اینکه ر...</td>\n      <td>به گزلرش همشهری آنلاین، عبدالرضا فرجی راد دربا...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>3271</th>\n      <td>سه‌شنبه ۲۰ اردیبهشت ۱۴۰۱ - ۱۷:۱۳</td>\n      <td>حمله سایبری به اینترنت ماهواه‌ای کار روسیه بود...</td>\n      <td>اتحادیه اروپا مدعی شد که حمله سایبری بزرگ علیه...</td>\n      <td>به گزارش همشهری آنلاین و به نقل خبرگزاری رویتر...</td>\n      <td>IT</td>\n    </tr>\n    <tr>\n      <th>571</th>\n      <td>یکشنبه ۲۴ بهمن ۱۴۰۰ - ۱۱:۲۹</td>\n      <td>حمله قریب‌الوقوع روسیه به اوکراین؟</td>\n      <td>یک مقام کاخ الیزه می‌گوید در تماس تلفنی رئیس ج...</td>\n      <td>به گزارش همشهری آنلاین به نقل از فارس، یک مقام...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>سه‌شنبه ۱۰ اسفند ۱۴۰۰ - ۱۳:۱۱</td>\n      <td>تازه‌ترین درخواست وزیر امور خارجه اوکراین علیه...</td>\n      <td>دیمیترو کولبا، وزیر امور خارجه اوکراین، پس از ...</td>\n      <td>به گزارش همشهری آنلاین و به نقل از گاردین، او ...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>جمعه ۶ اسفند ۱۴۰۰ - ۱۲:۱۹</td>\n      <td>ادعای وزیر دفاع انگلیس درباره نقشه روسیه برای ...</td>\n      <td>وزیر دفاع انگلیس در بیانیه‌ای مدعی شد، روسیه ق...</td>\n      <td>به گزارش همشهری آنلاین و به نقل از گاردین، بن ...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>جمعه ۶ اسفند ۱۴۰۰ - ۱۶:۰۷</td>\n      <td>پوتین: آماده مذاکره با اوکراین هستیم | موضع ری...</td>\n      <td>رئیس جمهور چین در یک تماس تلفنی با رئیس جمهور ...</td>\n      <td>به گزارش همشهری‌آنلاین به نقل از فارس، رسانه‌ه...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>شنبه ۱۷ اردیبهشت ۱۴۰۱ - ۱۶:۲۷</td>\n      <td>جنگ اوکراین روزانه چقدر برای روسیه آب می‌خورد؟</td>\n      <td>یک نشریه آمریکایی در گزارشی با اشاره به سومین ...</td>\n      <td>به گزارش همشهری‌آنلاین، ایرنا به نقل از نشریه ...</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>یکشنبه ۸ اسفند ۱۴۰۰ - ۱۶:۱۰</td>\n      <td>منتظر جنگ جهانی سوم باشیم؟ | امکان چریکی شدن ج...</td>\n      <td>جهانگیر کرمی، عضو هیات علمی دانشگاه تهران و کا...</td>\n      <td>همشهری‌آنلاین - اصغر صوفی: درگیری میان اوکراین...</td>\n      <td>World</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"روسیه به اوکراین حمله کرد\"\n",
    "preprocessed_query = ' '.join(preprocessor.preprocess(query))\n",
    "TF_IDF_model.predict(preprocessed_query, mini_dataset, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastText:\n",
    "\n",
    "    def __init__(self, method='skipgram'):\n",
    "        self.method = method\n",
    "        self.mean_embed = []\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, dataset):\n",
    "        with open('fasttext_train.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write('\\n'.join(list(map(lambda doc: ' '.join(doc), dataset))))\n",
    "        self.model = fasttext.train_unsupervised('fasttext_train.txt', self.method, minn=2, maxn=5)\n",
    "        os.remove('fasttext_train.txt')\n",
    "        for doc in dataset:\n",
    "            embed = np.mean(list(map(lambda word: self.model.get_word_vector(word), doc)), axis=0)\n",
    "            self.mean_embed.append(embed)\n",
    "        self.mean_embed = np.array(self.mean_embed)\n",
    "\n",
    "    def predict(self, query, dataset, k):\n",
    "        query_embed = np.mean(list(map(lambda word: self.model.get_word_vector(word), query)), axis=0)\n",
    "        dataset_sim = []\n",
    "        for doc in self.mean_embed:\n",
    "            doc_cosine_sim = self.cosine_sim(query_embed, doc)\n",
    "            dataset_sim.append(doc_cosine_sim)\n",
    "        idx = np.argsort(-np.array(dataset_sim))\n",
    "        return dataset.iloc[list(idx[:k])]\n",
    "\n",
    "    def cosine_sim(self, query, doc):\n",
    "        return np.dot(query, doc) / (np.linalg.norm(query) * np.linalg.norm(doc))\n",
    "\n",
    "    def save_FastText_model(self, path='FastText_model.bin'):\n",
    "        self.model.save_model(path)\n",
    "        np.save('FastText_mean_embed.npy', self.mean_embed)\n",
    "\n",
    "    def load_FastText_model(self, path=\"FastText_model.bin\"):\n",
    "        self.model = fasttext.load_model(path)\n",
    "        self.mean_embed = np.load('FastText_mean_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fasttext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [45]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m FastText_model \u001B[38;5;241m=\u001B[39m FastText()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mFastText_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocessed_texts\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [44]\u001B[0m, in \u001B[0;36mFastText.train\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfasttext_train.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m     10\u001B[0m     file\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m doc: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(doc), dataset))))\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mfasttext\u001B[49m\u001B[38;5;241m.\u001B[39mtrain_unsupervised(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfasttext_train.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod, minn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, maxn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     12\u001B[0m os\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfasttext_train.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m dataset:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'fasttext' is not defined"
     ]
    }
   ],
   "source": [
    "FastText_model = FastText()\n",
    "FastText_model.train(preprocessed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#FastText_model.save_ft_model()\n",
    "FastText_model.load_ft_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>intro</th>\n",
       "      <th>body</th>\n",
       "      <th>category-PER</th>\n",
       "      <th>category-ENG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57068</th>\n",
       "      <td>دوشنبه ۹ خرداد ۱۴۰۱ - ۰۶:۴۹</td>\n",
       "      <td>پیام تبریک سرمربی میلان ایتالیا به مجیدی و است...</td>\n",
       "      <td>سرمربی میلان به فرهاد مجیدی و بازیکنان استقلال...</td>\n",
       "      <td>به گزارش همشهری آنلاین استفانو پیولی سرمربی تی...</td>\n",
       "      <td>['ورزش', 'فوتبال ايران']</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49338</th>\n",
       "      <td>سه‌شنبه ۳ فروردین ۱۴۰۰ - ۰۹:۲۰</td>\n",
       "      <td>عکس | سلفی مجیدی با عضو جدید کادر فنی استقلال</td>\n",
       "      <td>همکار سرمربی استقلال در تیم ملی امید به کادرفن...</td>\n",
       "      <td>به گزارش همشهری‌آنلاین، فرشاد ماجدی به کادرفنی...</td>\n",
       "      <td>['ورزش', 'فوتبال ايران']</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72280</th>\n",
       "      <td>جمعه ۲۹ مرداد ۱۴۰۰ - ۲۲:۳۲</td>\n",
       "      <td>دستیار ایتالیایی مجیدی از ابتدای لیگ روی نیمکت...</td>\n",
       "      <td>گابریل پین با درخواست دوباره مجیدی به ایران خو...</td>\n",
       "      <td>به گزارش همشهری آنلاین یکی از خواسته های فرهاد...</td>\n",
       "      <td>['ورزش', 'فوتبال ايران']</td>\n",
       "      <td>LifeSkills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51162</th>\n",
       "      <td>جمعه ۲۹ مرداد ۱۴۰۰ - ۲۲:۳۲</td>\n",
       "      <td>دستیار ایتالیایی مجیدی از ابتدای لیگ روی نیمکت...</td>\n",
       "      <td>گابریل پین با درخواست دوباره مجیدی به ایران خو...</td>\n",
       "      <td>به گزارش همشهری آنلاین یکی از خواسته های فرهاد...</td>\n",
       "      <td>['ورزش', 'فوتبال ايران']</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56582</th>\n",
       "      <td>یکشنبه ۲۵ اردیبهشت ۱۴۰۱ - ۱۳:۵۱</td>\n",
       "      <td>ناراحتی برانکو از قهرمان نشدن پرسپولیس در لیگ ...</td>\n",
       "      <td>سرمربی سابق کروات پرسپولیس به قهرمان نشدن پرسپ...</td>\n",
       "      <td>به گزارش همشهری‌آنلاین، سرمربی کروات و سابق پر...</td>\n",
       "      <td>['ورزش', 'فوتبال ايران']</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  date  \\\n",
       "57068      دوشنبه ۹ خرداد ۱۴۰۱ - ۰۶:۴۹   \n",
       "49338   سه‌شنبه ۳ فروردین ۱۴۰۰ - ۰۹:۲۰   \n",
       "72280       جمعه ۲۹ مرداد ۱۴۰۰ - ۲۲:۳۲   \n",
       "51162       جمعه ۲۹ مرداد ۱۴۰۰ - ۲۲:۳۲   \n",
       "56582  یکشنبه ۲۵ اردیبهشت ۱۴۰۱ - ۱۳:۵۱   \n",
       "\n",
       "                                                   title  \\\n",
       "57068  پیام تبریک سرمربی میلان ایتالیا به مجیدی و است...   \n",
       "49338      عکس | سلفی مجیدی با عضو جدید کادر فنی استقلال   \n",
       "72280  دستیار ایتالیایی مجیدی از ابتدای لیگ روی نیمکت...   \n",
       "51162  دستیار ایتالیایی مجیدی از ابتدای لیگ روی نیمکت...   \n",
       "56582  ناراحتی برانکو از قهرمان نشدن پرسپولیس در لیگ ...   \n",
       "\n",
       "                                                   intro  \\\n",
       "57068  سرمربی میلان به فرهاد مجیدی و بازیکنان استقلال...   \n",
       "49338  همکار سرمربی استقلال در تیم ملی امید به کادرفن...   \n",
       "72280  گابریل پین با درخواست دوباره مجیدی به ایران خو...   \n",
       "51162  گابریل پین با درخواست دوباره مجیدی به ایران خو...   \n",
       "56582  سرمربی سابق کروات پرسپولیس به قهرمان نشدن پرسپ...   \n",
       "\n",
       "                                                    body  \\\n",
       "57068  به گزارش همشهری آنلاین استفانو پیولی سرمربی تی...   \n",
       "49338  به گزارش همشهری‌آنلاین، فرشاد ماجدی به کادرفنی...   \n",
       "72280  به گزارش همشهری آنلاین یکی از خواسته های فرهاد...   \n",
       "51162  به گزارش همشهری آنلاین یکی از خواسته های فرهاد...   \n",
       "56582  به گزارش همشهری‌آنلاین، سرمربی کروات و سابق پر...   \n",
       "\n",
       "                   category-PER category-ENG  \n",
       "57068  ['ورزش', 'فوتبال ايران']        Sport  \n",
       "49338  ['ورزش', 'فوتبال ايران']        Sport  \n",
       "72280  ['ورزش', 'فوتبال ايران']   LifeSkills  \n",
       "51162  ['ورزش', 'فوتبال ايران']        Sport  \n",
       "56582  ['ورزش', 'فوتبال ايران']        Sport  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"روسیه به اوکراین حمله کرد\"\n",
    "preprocessed_query = ' '.join(preprocessor.preprocess(query))\n",
    "FastText_model.predict(preprocessed_query, dataset, k=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}