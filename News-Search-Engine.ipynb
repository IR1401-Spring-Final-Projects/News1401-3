{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div dir=\"auto\" align=\"center\">\n",
    "    <h3>\n",
    "        بسم الله الرحمن الرحیم\n",
    "    </h3>\n",
    "    <br>\n",
    "    <h1>\n",
    "        <strong>\n",
    "            بازیابی پیشرفته اطلاعات\n",
    "        </strong>\n",
    "    </h1>\n",
    "    <h2>\n",
    "        <strong>\n",
    "            تمرین سوم (موتور جستجوی اخبار)\n",
    "        </strong>\n",
    "    </h2>\n",
    "    <br>\n",
    "    <h3>\n",
    "        محمد هجری - ٩٨١٠٦١٥٦\n",
    "        <br><br>\n",
    "        ارشان دلیلی - ٩٨١٠٥٧٥١\n",
    "        <br><br>\n",
    "        سروش جهان‌زاد - ٩٨١٠٠٣٨٩\n",
    "    </h3>\n",
    "    <br>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div>\n",
    "    <h3 style='direction:rtl;text-align:justify;'>\n",
    "        نصب و دسترسی به کتابخانه‌های مورد نیاز\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        با اجرای دو قطعه کد زیر، کتابخانه‌هایی که از آن‌ها در این تمرین استفاده شده است، نصب و قابل استفاده می‌شوند.\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (1.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.13.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (4.64.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: html5lib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from html5lib) (1.13.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from html5lib) (0.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install bs4\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div>\n",
    "    <h2 style='direction:rtl;text-align:justify;'>\n",
    "        ١. دریافت داده‌ها\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        در این تمرین، بیش از ٢٠٠ خبر از\n",
    "        <a href=\"https://www.hamshahrionline.ir/\"> وب‌سایت همشهری‌آنلاین </a>\n",
    "        گردآوری شده که در ١٠ دسته‌ی سیاسی، جهانی، اقتصادی، اجتماعی، شهری، ورزشی، علمی، فرهنگی، فناوری اطلاعات و مهارت‌های زندگی طبقه‌بندی شده‌اند.\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'Politics': 'سیاسی',\n",
    "    'World': 'جهانی',\n",
    "    'Economy': 'اقتصادی',\n",
    "    'Society': 'اجتماعی',\n",
    "    'City': 'شهری',\n",
    "    'Sport': 'ورزشی',\n",
    "    'Science': 'علمی',\n",
    "    'Culture': 'فرهنگی',\n",
    "    'IT': 'فناوری اطلاعات',\n",
    "    'LifeSkills': 'مهارت‌های زندگی',\n",
    "}"
   ],
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
<<<<<<< Updated upstream
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        برای دریافت داده‌ها یک ماژول Scraper ساخته‌ایم که اخبار مربوط به ١٠ دسته‌ی مذکور را در بازه‌ی زمانی تعیین شده، کراول کرده و در فایل dataset.csv ذخیره می‌کند. کد مربوط به این ماژول را در زیر مشاهده می‌کنید.\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
=======
>>>>>>> Stashed changes
   },
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "\n",
    "    def __init__(self, current_year, current_month):\n",
    "        self.current_year = current_year\n",
    "        self.current_month = current_month\n",
    "\n",
    "    def get_URL_content(self, URL):\n",
    "        while True:\n",
    "            try:\n",
<<<<<<< Updated upstream
    "                return requests.get(URL, timeout=5).content\n",
=======
    "                return requests.get(URL, timeout=10).content\n",
>>>>>>> Stashed changes
    "                break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def generate_page_URL(self, page_index, category, year, month):\n",
    "        tp = {'Politics': 6, 'World': 11, 'Economy': 10, 'Society': 5, 'City': 7,\n",
    "              'Sport': 9, 'Science': 20, 'Culture': 26, 'IT': 718, 'LifeSkills': 21}[category]\n",
    "        return f'https://www.hamshahrionline.ir/archive?pi={page_index}&tp={tp}&ty=1&ms=0&mn={month}&yr={year}'\n",
    "\n",
    "    def get_page_URLs_by_time(self, category, year, month):\n",
    "        URLs = []\n",
    "        page_index = 1\n",
    "        while True:\n",
    "            URL = self.generate_page_URL(page_index, category, year, month)\n",
    "            content = self.get_URL_content(URL)\n",
    "            if re.findall('pagination', str(content)):\n",
    "                URLs.append(URL)\n",
    "                page_index += 1\n",
    "            else:\n",
    "                break\n",
    "        return URLs\n",
    "\n",
    "    def get_page_URLs_since(self, category, year, month):\n",
    "        URLs = []\n",
    "        with tqdm() as pbar:\n",
    "            while True:\n",
    "                if month > 12:\n",
    "                    month = 1\n",
    "                    year += 1\n",
    "                pbar.set_description(f'[{category}] [Extracting page URLs] [Date: {year}/{month}]')\n",
    "                URLs_by_time = self.get_page_URLs_by_time(category, year, month)\n",
    "                if URLs_by_time:\n",
    "                    for URL in URLs_by_time:\n",
    "                        URLs.append(URL)\n",
    "                    month += 1\n",
    "                elif self.current_year > year or (self.current_year == year and self.current_month > month):\n",
    "                    month += 1\n",
    "                else:\n",
    "                    break\n",
    "        return URLs\n",
    "\n",
    "    def get_news_URLs_since(self, category, year, month):\n",
    "        news_URLs = []\n",
    "        page_URLs = self.get_page_URLs_since(category, year, month)\n",
    "        with tqdm(page_URLs) as pbar:\n",
    "            for page_URL in pbar:\n",
    "                content = self.get_URL_content(page_URL)\n",
    "                soup = BeautifulSoup(content, 'html5lib')\n",
    "                for item in soup.findAll('li', attrs={'class': 'news'}):\n",
    "                    URL = item.find('div', attrs={'class': 'desc'}).find('h3').find('a')['href']\n",
    "                    URL = 'https://www.hamshahrionline.ir' + URL\n",
    "                    news_URLs.append(URL)\n",
    "                pbar.set_description(f'[{category}] [Extracting news URLs] [{len(news_URLs)} news until now]')\n",
    "        return news_URLs\n",
    "\n",
    "    def parse_news(self, URL, category):\n",
    "        try:\n",
    "            content = self.get_URL_content(URL)\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            date = soup.find(\"div\", {\"class\": \"col-6 col-sm-4 col-xl-4 item-date\"}).span.text.strip()\n",
    "            title = soup.find(\"div\", {\"class\": \"item-title\"}).h1.text.strip()\n",
    "            intro = soup.find(\"p\", {\"class\": \"introtext\", \"itemprop\": \"description\"}).text.strip()\n",
    "            body = soup.find(\"div\", {\"class\": \"item-text\", \"itemprop\": \"articleBody\"}).text.strip()\n",
    "            category_PER = soup.find_all(\"li\", {\"class\": \"breadcrumb-item\"})\n",
    "            category_PER = list(map(lambda x: x.text.strip(), category_PER))[1:]\n",
    "            return {\n",
    "                'date': date,\n",
    "                'title': title,\n",
    "                'intro': intro,\n",
    "                'body': body,\n",
    "                'category-PER': category_PER,\n",
    "                'category-ENG': category,\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def scrape(self, from_year, from_month):\n",
    "        categories = ['Politics', 'World', 'Economy', 'Society', 'City',\n",
    "                      'Sport', 'Science', 'Culture', 'IT', 'LifeSkills']\n",
    "        news = []\n",
    "        for category in categories:\n",
    "            URLs = self.get_news_URLs_since(category, from_year, from_month)\n",
    "            with tqdm(URLs) as pbar:\n",
    "                pbar.set_description(f'[{category}] [Scraping news]')\n",
    "                for URL in pbar:\n",
<<<<<<< Updated upstream
    "                    news.append(self.parse_news(URL, category))\n",
    "        news = list(filter(None, news))\n",
    "        pd.DataFrame(news).to_csv(f'dataset.csv', encoding='utf-8')"
=======
    "                    news.append(self.parse_news(URL))\n",
    "            category_news[category] = news\n",
    "            df = pd.DataFrame(news)\n",
    "            df.to_csv(f\"{category}_dataset.csv\", encoding='utf-8')\n",
    "        return category_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Society] [Extracting page URLs] [Date: 1401/4]: : 0it [02:47, ?it/s] \n",
      "[Society] [Extracting news URLs] [14259 news until now]: 100%|██████████| 484/484 [04:36<00:00,  1.75it/s]\n",
      "[Society] [Scraping news]: 100%|██████████| 14259/14259 [3:07:13<00:00,  1.27it/s]  \n",
      "[City] [Extracting page URLs] [Date: 1401/4]: : 0it [03:18, ?it/s] \n",
      "[City] [Extracting news URLs] [4323 news until now]: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
      "[City] [Scraping news]: 100%|██████████| 4323/4323 [54:03<00:00,  1.33it/s]  \n",
      "[LifeSkills] [Extracting page URLs] [Date: 1401/4]: : 0it [08:44, ?it/s] \n",
      "[LifeSkills] [Extracting news URLs] [13585 news until now]: 100%|██████████| 460/460 [03:58<00:00,  1.93it/s]\n",
      "[LifeSkills] [Scraping news]: 100%|██████████| 13585/13585 [2:53:44<00:00,  1.30it/s]  \n"
     ]
    }
   ],
   "source": [
    "scraper = Scraper(current_year=1401, current_month=3)\n",
    "category_news = scraper.scrape(from_year=1400, from_month=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(category_news[\"Society\"])\n",
    "# df.to_csv(f\"Society_dataset.csv\", encoding='utf-8')\n",
    "df.to_json(f\"Society_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Society_dataset.json\")\n",
    "df.to_csv(f\"Society_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>intro</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۲۱:۳۷</td>\n",
       "      <td>ساخت سردخانه‌های جدید در بهشت زهرا تهران در شر...</td>\n",
       "      <td>رئیس سازمان پیشگیری و مدیریت بحران شهرداری تهر...</td>\n",
       "      <td>به گزارش همشهری آنلاین، \"رضا کرمی محمدی\" رئیس ...</td>\n",
       "      <td>['جامعه', 'بهداشت و درمان']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۲۰:۵۶</td>\n",
       "      <td>ساخت ویلاهای اشرافی به جای مرکز آموزشی!</td>\n",
       "      <td>رئیس کل دادگستری استان تهران گفت: در رودبار قص...</td>\n",
       "      <td>به گزارش همشهری آنلاین به نقل از میزان، محمد ج...</td>\n",
       "      <td>['سياست', 'حقوقی و قضایی']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۳۲</td>\n",
       "      <td>رای شورا به اصلاح اساسنامه ۱۹ سازمان وابسته به...</td>\n",
       "      <td>شورای شهر تهران امروز کلیات لایحه اصلاح اساسنا...</td>\n",
       "      <td>به گزارش همشهری آنلاین، در جلسه امروز شورا، لا...</td>\n",
       "      <td>['شهر', 'شورای شهر']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۳۱</td>\n",
       "      <td>نصب ۹۳۵ آب گرمکن خورشیدی در اماکن عمومی تهران ...</td>\n",
       "      <td>معاون اداره کل محیط زیست شهرداری تهران با اشار...</td>\n",
       "      <td>به گزارش همشهری آنلاین به نقل از مهر؛ «سعید اح...</td>\n",
       "      <td>['شهر', 'شهری']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۲۹</td>\n",
       "      <td>حناچی: دفن زباله با ساخت نیروگاه زباله سوز ۸۰۰...</td>\n",
       "      <td>شهردار تهران با اشاره به اینکه روزانه در تهران...</td>\n",
       "      <td>به گزارش همشهری آنلاین به نقل از پایگاه خبری ش...</td>\n",
       "      <td>['شهر', 'شهردار']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>4318</td>\n",
       "      <td>یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۵۲</td>\n",
       "      <td>پیش‌بینی ۴۰ نمایشگاه در مجموعه شهر آفتاب برای ...</td>\n",
       "      <td>رئیس کمیسیون نظارت و حقوقی شورای اسلامی شهر ته...</td>\n",
       "      <td>به گزارش همشهری آنلاین، مهدی اقراریان در شصت و...</td>\n",
       "      <td>['شهر', 'شهری']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>4319</td>\n",
       "      <td>یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۳۷</td>\n",
       "      <td>هوای تهران همچنان ناسالم برای گروه‌های حساس</td>\n",
       "      <td>بر اساس اعلام شرکت کنترل کیفیت هوای تهران، کیف...</td>\n",
       "      <td>به گزارش همشهری آنلاین، شرکت کنترل کیفیت هوای ...</td>\n",
       "      <td>['شهر', 'شهری']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>4320</td>\n",
       "      <td>یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۱۵</td>\n",
       "      <td>مهلت پرداخت فرم‌های عوارض ساختمانی تا پایان خر...</td>\n",
       "      <td>طبق مصوبه امروز نمایندگان شورای شهر تهران، مهل...</td>\n",
       "      <td>به گزارش همشهری آنلاین، مهدی چمران در شصت و چه...</td>\n",
       "      <td>['شهر', 'شورای شهر']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>4321</td>\n",
       "      <td>یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۰۰</td>\n",
       "      <td>نقشه طهران  در سال ۱۲۷۷ خورشیدی را ببینید | پا...</td>\n",
       "      <td>این نقشه تهران و روستاهای اطراف آن در سال ۱۲۷۷...</td>\n",
       "      <td>همشهری آنلاین - ثریا روزبهانی:از سال۱۲۷۰ تا پا...</td>\n",
       "      <td>['محله', 'کوچه پس کوچه']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>4322</td>\n",
       "      <td>یکشنبه ۱ خرداد ۱۴۰۱ - ۰۹:۲۷</td>\n",
       "      <td>چمران به شورای شهر تهران بازگشت</td>\n",
       "      <td>مهدی چمران پس از دو ماه غیبت در شورای شهری تهر...</td>\n",
       "      <td>به گزارش همشهری آنلاین، صبح امروز در شصت‌وچهار...</td>\n",
       "      <td>['شهر', 'شورای شهر']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4323 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                             date  \\\n",
       "0              0  سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۲۱:۳۷   \n",
       "1              1  سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۲۰:۵۶   \n",
       "2              2  سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۳۲   \n",
       "3              3  سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۳۱   \n",
       "4              4  سه‌شنبه ۳۱ فروردین ۱۴۰۰ - ۱۹:۲۹   \n",
       "...          ...                              ...   \n",
       "4318        4318      یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۵۲   \n",
       "4319        4319      یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۳۷   \n",
       "4320        4320      یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۱۵   \n",
       "4321        4321      یکشنبه ۱ خرداد ۱۴۰۱ - ۱۰:۰۰   \n",
       "4322        4322      یکشنبه ۱ خرداد ۱۴۰۱ - ۰۹:۲۷   \n",
       "\n",
       "                                                  title  \\\n",
       "0     ساخت سردخانه‌های جدید در بهشت زهرا تهران در شر...   \n",
       "1               ساخت ویلاهای اشرافی به جای مرکز آموزشی!   \n",
       "2     رای شورا به اصلاح اساسنامه ۱۹ سازمان وابسته به...   \n",
       "3     نصب ۹۳۵ آب گرمکن خورشیدی در اماکن عمومی تهران ...   \n",
       "4     حناچی: دفن زباله با ساخت نیروگاه زباله سوز ۸۰۰...   \n",
       "...                                                 ...   \n",
       "4318  پیش‌بینی ۴۰ نمایشگاه در مجموعه شهر آفتاب برای ...   \n",
       "4319        هوای تهران همچنان ناسالم برای گروه‌های حساس   \n",
       "4320  مهلت پرداخت فرم‌های عوارض ساختمانی تا پایان خر...   \n",
       "4321  نقشه طهران  در سال ۱۲۷۷ خورشیدی را ببینید | پا...   \n",
       "4322                    چمران به شورای شهر تهران بازگشت   \n",
       "\n",
       "                                                  intro  \\\n",
       "0     رئیس سازمان پیشگیری و مدیریت بحران شهرداری تهر...   \n",
       "1     رئیس کل دادگستری استان تهران گفت: در رودبار قص...   \n",
       "2     شورای شهر تهران امروز کلیات لایحه اصلاح اساسنا...   \n",
       "3     معاون اداره کل محیط زیست شهرداری تهران با اشار...   \n",
       "4     شهردار تهران با اشاره به اینکه روزانه در تهران...   \n",
       "...                                                 ...   \n",
       "4318  رئیس کمیسیون نظارت و حقوقی شورای اسلامی شهر ته...   \n",
       "4319  بر اساس اعلام شرکت کنترل کیفیت هوای تهران، کیف...   \n",
       "4320  طبق مصوبه امروز نمایندگان شورای شهر تهران، مهل...   \n",
       "4321  این نقشه تهران و روستاهای اطراف آن در سال ۱۲۷۷...   \n",
       "4322  مهدی چمران پس از دو ماه غیبت در شورای شهری تهر...   \n",
       "\n",
       "                                                   body  \\\n",
       "0     به گزارش همشهری آنلاین، \"رضا کرمی محمدی\" رئیس ...   \n",
       "1     به گزارش همشهری آنلاین به نقل از میزان، محمد ج...   \n",
       "2     به گزارش همشهری آنلاین، در جلسه امروز شورا، لا...   \n",
       "3     به گزارش همشهری آنلاین به نقل از مهر؛ «سعید اح...   \n",
       "4     به گزارش همشهری آنلاین به نقل از پایگاه خبری ش...   \n",
       "...                                                 ...   \n",
       "4318  به گزارش همشهری آنلاین، مهدی اقراریان در شصت و...   \n",
       "4319  به گزارش همشهری آنلاین، شرکت کنترل کیفیت هوای ...   \n",
       "4320  به گزارش همشهری آنلاین، مهدی چمران در شصت و چه...   \n",
       "4321  همشهری آنلاین - ثریا روزبهانی:از سال۱۲۷۰ تا پا...   \n",
       "4322  به گزارش همشهری آنلاین، صبح امروز در شصت‌وچهار...   \n",
       "\n",
       "                         category  \n",
       "0     ['جامعه', 'بهداشت و درمان']  \n",
       "1      ['سياست', 'حقوقی و قضایی']  \n",
       "2            ['شهر', 'شورای شهر']  \n",
       "3                 ['شهر', 'شهری']  \n",
       "4               ['شهر', 'شهردار']  \n",
       "...                           ...  \n",
       "4318              ['شهر', 'شهری']  \n",
       "4319              ['شهر', 'شهری']  \n",
       "4320         ['شهر', 'شورای شهر']  \n",
       "4321     ['محله', 'کوچه پس کوچه']  \n",
       "4322         ['شهر', 'شورای شهر']  \n",
       "\n",
       "[4323 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"City_dataset.csv\")\n",
    "df2"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "        با اجرای قطعه کد زیر، یک instance از ماژول Scraper ایجاد شده و شروع به دریافت و ذخیره‌سازی داده‌ها می‌کند. خبرهای دریافت شده همگی مربوط به قرن جدید، از سال ١٤٠٠ به بعد هستند.\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scraper = Scraper(current_year=1401, current_month=3)\n",
    "scraper.scrape(from_year=1400, from_month=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "    بعد از ذخیره شدن داده‌ها در فایل dataset.csv، آن‌ها را از روی فایل خوانده و وارد برنامه می‌کنیم.\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def read_dataset_from_file():\n",
    "    dataset = []\n",
    "    with open(\"dataset.csv\", encoding=\"utf-8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            data = dict(zip(header[1:], row[1:]))\n",
    "            dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = read_dataset_from_file()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div dir=\"auto\" align=\"justify\">\n",
    "    <p style='direction:rtl;text-align:justify;'>\n",
    "    با اجرای قطعه کد زیر، تعداد خبرهای هر دسته و تعداد کل خبرها را می‌توان مشاهده کرد\n",
    "    </p>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def display_dataset_info():\n",
    "    global CATEGORIES\n",
    "\n",
    "    length_dict = {key: 0 for key in CATEGORIES.keys()}\n",
    "    for data in dataset:\n",
    "        length_dict[data['category-ENG']] += 1\n",
    "\n",
    "    df_dict = {\n",
    "        'دسته': CATEGORIES.values(),\n",
    "        'تعداد': length_dict.values(),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df.index += 1\n",
    "    df.loc[0] = ['کل خبرها', len(dataset)]\n",
    "    df = df.sort_index()\n",
    "    display(df)\n",
    "\n",
    "\n",
    "display_dataset_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "               دسته  تعداد\n0          کل خبرها    130\n1             سیاسی      0\n2             جهانی      0\n3           اقتصادی      0\n4           اجتماعی      0\n5              شهری      0\n6             ورزشی      0\n7              علمی      0\n8            فرهنگی      0\n9    فناوری اطلاعات    130\n10  مهارت‌های زندگی      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>دسته</th>\n      <th>تعداد</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>کل خبرها</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سیاسی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>جهانی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>اقتصادی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اجتماعی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>شهری</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ورزشی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>علمی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>فرهنگی</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>فناوری اطلاعات</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>مهارت‌های زندگی</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for category, news in category_news.items():\n",
    "    df = pd.DataFrame(news)\n",
    "    df.to_csv(f\"{category}_dataset.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'date', 'title', 'intro', 'body', 'category-PER', 'category-ENG']\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "IT\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file = open(\"dataset.csv\", encoding=\"utf-8\")\n",
    "csvreader = csv.reader(file)\n",
    "header = next(csvreader)\n",
    "print(header)\n",
    "rows = []\n",
    "for row in csvreader:\n",
    "    rows.append(row)\n",
    "    print(row[-1])\n",
    "print(len(rows))\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Politics_dataset.json', 'w') as file:\n",
    "    json.dump(category_news['Politics'], file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "news_info = ['date', 'title', 'intro', 'body', 'category']\n",
    "with open('Society_dataset.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = news_info)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(category_news[\"Society\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'به گزارش همشهری آنلاین به نقل از ایسنا،\\xa0در نامه دکتر سیدعلیرضا مرندی خطاب به دکتر سعید نمکی آمده است: با احترام، نظر به اهمیت بسیار بالای نقش ایمن سازی جامعه\\xa0علیه ویروس کرونا و با توجه به اشتیاق قاطبه مردم به دریافت واکسن، به اختصار، به چند نکته مهم اشاره می کنم. این اقدام بسیار ضروری، نیازمند برنامه ریزی کاملاً دقیق و مشارکت بعضی نهادها در امور برنامه ریزی و اجرا است (در ارتباط با نظم، امنیت، نظارت و... و طبیعتاً نه مسائل فنی). - بدون هیچ گونه تردیدی، استفاده از شبکه بهداشتی درمانی «تنها» راه انجام این مسئولیت خطیر است. - جهت اجرایی کردن توصیه و دستور مقام معظم رهبری، بهتر است از فرصت محدود باقی مانده و قبل از آن که حجم لازم واکسن آماده شود، هرچه سریع تر، به ترمیم، تکمیل، اصلاح، تقویت و اعتلای شبکه بهداشتی درمانی پرداخته شود، تا آمادگی های لازم کاملاً فراهم شود. می توان نوعی رقابت بین دانشگاه های علوم پزشکی برای عملیاتی کردن این امر مهم ایجاد کرد. این اقدام بسیار ارزشمند، علاوه بر پیشگیری از هرگونه مشکل احتمالی، و نیز پاسخگویی مطلوب به نیازهای امر واکسیناسیون عمومی، موجب سرمایه گذاری بسیار مهمی برای آینده کشور نیز خواهد بود. - از درگیر نمودن بخش خصوصی، به شدت پرهیز شود، چه در امر خرید واکسن و چه در امر توزیع و حتی تزریق آن که متأسفانه خطر رانت خواری و سوء استفاده های کلان در خرید، فساد در حمل و نگهداری و نیز کیفیت واکسن خریداری شده بسیار زیاد خواهد بود. در امر توزیع هم احتمال ورود به بازار سیاه و در نتیجه محروم ماندن اقشار آسیب پذیر که قدرت خرید واکسن را ندارند، بسیار زیاد خواهد بود و عملاً احتمال پاسخگویی مطلوب توسط بخش خصوصی هم وجود نخواهد داشت. - قطعاً واکسن و واکسیناسیون باید کاملاً رایگان و فاقد هرگونه هزینه ای برای آحاد مردم باشد. - توصیه می شود از بسیج جامعه پزشکی و نیروی بسیج سپاه پاسداران انقلاب اسلامی جهت همکاری های لازم به منظور کسب اعتماد بیشتر مردم، حفظ نظم و آرامش، نظارت بر توزیع عادلانه واکسیناسیون و امثال آن استفاده شود. - لازم است برنامه نرم افزاری قابل اعتمادی جهت ثبت و ردیابی آنهایی که واکسینه می شوند از طریق ثبت نام، نام خانوادگی، سن، شناسه ملی و کدی که گویای اولویت دریافت واکسن باشد تهیه شود. توصیه می شود قبل از استفاده از سامانه مزبور، راستی آزمایی لازم، انجام شود. -کارکنان و همه آنهایی که در امر تزریق واکسن دخالت مستقیم دارند، باید آموزش های لازم را دیده و بر نحوه عملکردشان نظارت شود. متاسفانه در مشاهده جریان کارآزمایی های بالینی، نحوه تزریق واکسن در تلویزیون، در بسیاری موارد اشکالاتی در نحوه عملکردشان را نشان داد، نظیر نحوه مصرف پنبه الکل و غیره توسط افرادی که کار تزریق را انجام می دادند. - بهتر است وزارت محترم بهداشت، درمان و آموزش پزشکی برای هر دانشگاه یا دانشکده علوم پزشکی حداقل ۲ ناظر پیش بینی کند، تا با استفاده از فرم های تنظیم شده و انتخاب راندم افراد واکسینه شده، بتوانند گزارش های منظمی را برای آن وزارتخانه محترم تهیه و ارائه نمایند. - پیش بینی های لازم برای شنیدن و پاسخگویی به نظرات و پیشنهادهای مردم در تمام طول مدت واکسیناسیون انجام شود. - از آنجا که منابع تهیه و تولید واکسن ها متفاوت است، هرگونه بحث و نظر در مورد میزان تاثیر هر یک از انواع واکسن ها، فقط در محافل علمی و کاملاً خصوصی صورت پذیرد و از مغشوش کردن اذهان مردم در این مورد و یا موارد مشابه، به شدت پرهیز شود. - حتماً امکان ثبت هرگونه عارضه احتمالی (اعم از آنی، کوتاه مدت، میان مدت یا درازمدت) که ناشی از واکسیناسیون باشد فراهم گردد و فرم ها و گزارش های\\xa0مزبور مستمراً به استحضار مسئولان محترم وزارتخانه برسد. - در مورد اولویت بندی مردم در امر دریافت واکسن، ضمن استفاده از تجربیات سایر کشورها و نظر\\xa0سازمان جهانی بهداشت که بسیار ارزشمند است، وضعیت کشور را کاملا در نظر گرفته و در صورت ضرورت با مقاماتی که ممکن است پیشنهادهایی داشته باشند، مشورت قبلی به عمل آید که در ضمن اجرا، ذهن مردم با شنیدن نظرهای متفاوت، مغشوش نشوند. - مطلب بسیار مهم دیگر این که، توجه لازم داشته باشید که مساله ای بسیار تاثیرگذار یعنی انتخابات و جابه جایی دولت در پیش است. پیش بینی اقدامات باید به گونه ای باشد که هرگونه جابه جایی، کوچک ترین خللی در امر واکسیناسیون مردم ایجاد نکند. بهره بردن از حضور افراد یا نهادی که با تغییر دولت تعویض نخواهند شد، می تواند به ادامه اجرای موفق واکسیناسیون کمک کند.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Society_dataset.csv\")\n",
    "test = df.loc[0]['body']\n",
    "test = test.replace('\\u200c', ' ')\n",
    "test = test.replace('\\n', ' ')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df.to_csv(\"test.csv\",index=False,sep=\"\\\\\", encoding='utf-8', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
